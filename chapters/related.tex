\paragraph{} There is a wealth of prior theoretical and practical research that form an essential background to the work presented here. To provide adequate grounding, a handful of the most notable shall be discussed --- these are split into two distinct fields, \textit{Information Flow Control} and Intel SGX. To the best of our knowledge, little study has been conducted in this overlap, but where it exists, it will be highlighted as appropriate.


\section{\textit{Flume} and \textit{CamFlow}}
\paragraph{} Both \textit{Flume}~[X] and \textit{CamFlow}~[Y] present practical DIFC systems for generic, OS-level protection in Linux. The models they use are not too dissimilar, with \textit{CamFlow} adopting and refining the basic \textit{Flume} approach. A detailed overview of the \textit{CamFlow} model has already been presented in ยง~\ref{sec:ifc}, but the difference in how the two works were implemented are important to understand.

\paragraph{Flume} \textit{Flume} takes the form of a userspace reference monitor. Processes confined by Flume are not able to perform most \textit{syscalls} directly --- an \textit{interposition layer} replaces \textit{syscalls} with IPC to the reference monitor, which enforcing IFC policies and ensuring operation safety on processes' behalf. The majority of complexity lies in the reference monitor, with its LSM only a small auxiliary companion. The authors report a 30-40\% overhead.

\paragraph{CamFlow} Contrasting with \textit{Flume}, the \textit{CamFlow} core IFC implementation lies entirely within its LSM, efficiently exploiting kernel functionality to minimise the overhead it creates. It reports an 11\% average overhead for file operations in microbenchmark tests.


\subsubsection{Other IFC Systems}
\paragraph{} Many different approaches to IFC have been published over the years; the most influential to this project will be briefly summarised.

\paragraph{} \textit{Asbestos}, a prototype operating system by Krohn et al.~[X] that provides entity labelling and isolation as an OS primitive. Applications express individual policies via a custom kernel interface, and all dataflow is protected, including IPC and system-wide information flows. Additionally, a novel event abstraction and sub-process \textit{security contexts} allows processes to act on behalf of multiple entities. \textit{HiStar} (Zeldovich et al.~[Y]) builds on the \textit{Asbestos} model, minimising the size of the system's TCB --- the system has no notion of \textit{superuser}, with no code other than the kernel being fully trusted. An important consequence of this is that the risk of data leaking via \textit{covert channels} is drastically reduced. \textit{DStar} (Zeldovich et al.~[Z]) translates \textit{HiStar} into a distributed context, translating labels between IFC-enabled hosts with the help of a globally-meaningful set of tags. In contrast, \textit{Aeolus} (Cheng et al.~[A]), derived from \textit{Asbestos}, deploys a common TCB across all nodes in a distributed system to enforce IFC; it filters I/O and both inter- and intra- process communication.

\paragraph{} Laminar (Roy et al.~[B]) takes a similar approach to \textit{Flume}, using an LSM for policy enforcement, but extends it with customisation to the JVM\footnote{Java Virtual Machine} to support thread-level isolation and heap-object protection. This approach has proved powerful in applying DIFC to popular processing systems such as \textit{MapReduce}~[X] and \textit{Hadoop}~[Y].


\section{Interoperation between Linux and SGX} 
\paragraph{} The relationship between SGX and Linux has at times been difficult; Intel has been attempting to upstream \textit{isgx}, the SGX driver, into the mainline kernel for 6 years.\footnote{The \textit{linux-sgx} patch set is currently in its $32^{\text{nd}}$ revision; \url{https://lore.kernel.org/linux-sgx/}.} A source of extreme friction lies in the fact that enclaves are not operable in ring 0, forcing research seeking to use SGX to harden the kernel itself to be creative about how to integrate it.

\paragraph{} The \textit{TresorSGX}~[X] project was one of the first to consider the practicalities of this relationship seriously, constructing an externalised interface for kernel functionality to be offloaded to an enclave via a specialised kernel module. Mainly focussing on disk encryption, the prototype achieved its security goals but struggled with performance, only being able to perform at 1\% the bandwidth its kernel-embedded counterpart. As concluded by the authors, the most prevalent performance hit came from kernel $\leftrightarrow$ enclave communication overhead, made worse by the need to exit and reenter kernel-mode.


\paragraph{} Various other studies touch upon these issues, including:

\begin{itemize}
    \item \textit{Custos} (Paccagnella et al.~[X]); tamper-detection for audit logs using SGX. The design attaches itself to the pre-existing Linux Audit Framework, deliberately avoiding execution tied to the kernel. Performance overheads are declared as $2-7$\%. 
    \item \textit{DelegaTEE} (Matetic et al.~[Y]); credential delegation between two computer systems by enforcing either centrally brokered or P2P\footnote{Peer to peer.} \textit{discretionary access control}. The system does not operate at the OS-layer, but presents an effective capability-sharing system for modified applications via an SGX mediator.
    \item \textit{NeXUS} (Djoko et al.~[Z]); practical access control for remote storage systems such as \textit{Google Drive}. The design uses a \textit{stackable} filesystem to interface with encrypted volumes --- SGX is used to protect and share these encryption keys. The authors report $\times 2$ performance overhead.
\end{itemize}


\section{Dataflow Protection using SGX}
\paragraph{} Research into applying the protections afforded by SGX to large-scale distributed computation has been fervent in the past few years --- a handful of prominent projects are here detailed. 

\begin{itemize}
    \item \textit{SCONE}~[X] presents a secure container framework for \textit{Docker}.~[Y] Using a secured version of the standard library for C it transparently encrypts/decrypts I/O crossing the container's boundary. The authors claim $\times 0.6-1.2$ the performance of native throughput.
    \item \textit{VC3}~[X] secures \textit{Hadoop} \textit{MapReduce} computations --- the \textit{Hadoop} platform is not considered part of the TCB, thus allowing the system's security invariants to remain unaffected if it were to be compromised. The reported performance overhead is stated to be 8\% (for full read/write integrity).
    \item The \textit{Maru} project~[X] added support for running distributed \textit{Apache Spark} in SGX enclaves. Data residing outside of a worker in \textit{HDFS} is sealed, removing the needs for the need for \textit{Hadoop} to be a part of the TCB. A notably difficulty faced was porting the \textit{JVM}\footnote{Java Virtual Machine} to function efficiently inside an enclave; SGXv1 restricts the EPC size to 128MB, severely penalising applications that struggle to run in relatively small memory footprints.
    \item \textit{Ryoan}~[X] provides a distributed sandbox environment to confine untrusted applications running on sensitive data in the cloud; a specific use case is computation outsourcing. It uses \textit{confining labels} to create a weakened form of IFC tracking; processing nodes must be stateless and once tainted by a request cannot access resources outside the execution environment. Enforcement is managed both by SGX and \textit{NaCl}~[X] for the host application. 
\end{itemize}

